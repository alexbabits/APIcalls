{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'requests' is an HTTP library allows for HTTP requests easily.\n",
    "%pip install requests\n",
    "import requests\n",
    "# bs4 is a library for pulling data out of HTML and XML files.\n",
    "%pip install beautifulsoup4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NY is 0.00 m/s less windy than Detroit\n",
      "NY feels 16.74 degrees Fahrenheit hotter than Detroit\n",
      "{'coord': {'lon': -83.0458, 'lat': 42.3314}, 'weather': [{'id': 804, 'main': 'Clouds', 'description': 'overcast clouds', 'icon': '04d'}], 'base': 'stations', 'main': {'temp': 275.39, 'feels_like': 269.48, 'temp_min': 273.73, 'temp_max': 276.48, 'pressure': 1009, 'humidity': 70}, 'visibility': 10000, 'wind': {'speed': 8.75, 'deg': 280, 'gust': 13.89}, 'clouds': {'all': 100}, 'dt': 1681828599, 'sys': {'type': 2, 'id': 2006979, 'country': 'US', 'sunrise': 1681814800, 'sunset': 1681863362}, 'timezone': -14400, 'id': 4990729, 'name': 'Detroit', 'cod': 200}\n",
      "{'coord': {'lon': -74.006, 'lat': 40.7143}, 'weather': [{'id': 804, 'main': 'Clouds', 'description': 'overcast clouds', 'icon': '04d'}], 'base': 'stations', 'main': {'temp': 284.69, 'feels_like': 283.23, 'temp_min': 281.95, 'temp_max': 287.05, 'pressure': 1007, 'humidity': 51}, 'visibility': 10000, 'wind': {'speed': 8.75, 'deg': 250, 'gust': 11.83}, 'clouds': {'all': 100}, 'dt': 1681828000, 'sys': {'type': 2, 'id': 2008101, 'country': 'US', 'sunrise': 1681812774, 'sunset': 1681861049}, 'timezone': -14400, 'id': 5128581, 'name': 'New York', 'cod': 200}\n"
     ]
    }
   ],
   "source": [
    "# Grab some weather data using an API key\n",
    "api_key = \"31d06fc3e89fafdf23d06abe618bb61f\"\n",
    "city_1 = \"Detroit\"\n",
    "city_2 = \"New York\"\n",
    "\n",
    "# City_1\n",
    "url = f\"http://api.openweathermap.org/data/2.5/weather?q={city_1}&appid={api_key}\"\n",
    "response = requests.get(url)\n",
    "data_city_1 = response.json()\n",
    "\n",
    "# City_2\n",
    "url = f\"http://api.openweathermap.org/data/2.5/weather?q={city_2}&appid={api_key}\"\n",
    "response = requests.get(url)\n",
    "data_city_2 = response.json()\n",
    "\n",
    "# Access Data\n",
    "detroit_temp_feels_like = (data_city_1['main']['temp'] - 273.15) * 1.8 + 32\n",
    "new_york_temp_feels_like = (data_city_2['main']['temp'] - 273.15) * 1.8 + 32\n",
    "detroit_wind_speed = data_city_1['wind']['speed']\n",
    "new_york_wind_speed = data_city_2['wind']['speed']\n",
    "\n",
    "# Calculate values\n",
    "wind_speed_difference = new_york_wind_speed - detroit_wind_speed\n",
    "temp_feels_like_difference = new_york_temp_feels_like - detroit_temp_feels_like\n",
    "\n",
    "# Print the results\n",
    "print(f\"NY is {wind_speed_difference:.2f} m/s less windy than Detroit\")\n",
    "print(f\"NY feels {temp_feels_like_difference:.2f} degrees Fahrenheit hotter than Detroit\")\n",
    "\n",
    "# Default Units: Temperature: Kelvin. Pressure: Millibar. Visibility: Kilometers. Wind Speed: m/s. Wind Direction: Degrees (180 = South)\n",
    "print(data_city_1) \n",
    "print(data_city_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Doctors cannot believe Ralph Yarl survived shooting\n",
      "2.Doctors cannot believe Ralph Yarl survived shooting\n",
      "3.Brother died saving birthday girl's life in US shooting\n",
      "4.'Someone must know': Questions remain in Dadeville\n",
      "5.Putin visits occupied Kherson region in Ukraine\n",
      "6.Woman shot dead after pulling into wrong driveway\n",
      "7.Who didn't make the coronation guest list? Take our quiz\n",
      "8.Russian court rejects detained US journalist appeal\n",
      "9.India court hears historic same sex marriage case\n",
      "10.US accuses Brazil's Lula of parroting war propaganda\n",
      "11.US diplomatic convoy attacked in Sudan - Blinken\n",
      "12.No water, no light, as Sudan conflict rages on\n",
      "13.US diplomatic convoy attacked in Sudan - Blinken\n",
      "14.No water, no light, as Sudan conflict rages on\n",
      "15.Jamie Foxx still in hospital in US\n",
      "16.Beef actor's rape comments removed online\n",
      "17.EY cuts 3,000 jobs in US blaming 'overcapacity'\n",
      "18.How Republicans intend to solve mass shootings\n",
      "19.BBC World News TV\n",
      "20.BBC World Service Radio\n",
      "21.Key players in the $1.6bn lawsuit against Fox\n",
      "22.What we know about Alabama shooting victims\n",
      "23.Marathon runners get engaged at finish line\n",
      "24.Huge cocaine haul found floating in sea near Sicily\n",
      "25.Pink door woman sad after being forced to repaint\n",
      "26.Did the US-Ukraine leaks reveal anything valuable?\n",
      "27.Realities dash hopes for Israel-Palestinian peace\n",
      "28.'I thought we'd die' - Sudan patients cry for help\n",
      "29.NZ pilot kidnapping highlights intense insurgency\n",
      "30.‘We'll find you and we won't let you live’ – a team’s fight to exist\n",
      "31.How LinkedIn is changing and why some are not happy\n",
      "32.Fighting hits Khartoum neighbourhoods - maps and images\n",
      "33.The family secrets kept by generations\n",
      "34.The anxiety of being replaced by AI\n",
      "35.The beloved dessert rebuilding Turkey\n",
      "36.The hunt for India's stolen treasures\n",
      "37.Why some people's pain is ignored\n",
      "38.Why 'home co-working' is taking off\n",
      "39.Britain's 'cool' new seaside towns\n",
      "40.News daily newsletter\n",
      "41.Mobile app\n",
      "42.Get in touch\n"
     ]
    }
   ],
   "source": [
    "# Grab some headlines from a website by downloading and parsing HTML with BeautifulSoup\n",
    "url = \"https://www.bbc.com/news\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "headlines = soup.find_all(\"h3\")\n",
    "\n",
    "for idx, headline in enumerate(headlines, start=1):\n",
    "    print(f\"{idx}.{headline.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Alex Babits\n",
      "Location: Test Location\n",
      "Company: Test Company\n",
      "Bio: Hello. This is a test bio I'm using to learn about Github's personal access tokens. Testing 1 2 3. Testing 1 2 3.\n"
     ]
    }
   ],
   "source": [
    "# Web Scraping with token-based authentication (GitHub's Personal Access Token) with Python requests and BeautifulSoup\n",
    "\n",
    "token = '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'\n",
    "headers = {'Authorization': f'token {token}'}\n",
    "\n",
    "username = 'alexbabits'\n",
    "url = f'https://api.github.com/users/{username}'\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(f\"Name: {data['name']}\")\n",
    "    print(f\"Location: {data['location']}\")\n",
    "    print(f\"Company: {data['company']}\")\n",
    "    print(f\"Bio: {data['bio']}\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
